# ğŸ¤– AI-Powered Customer Support Chatbot (Local LLM - Mistral)

This project is a **fully offline AI chatbot** built using **Mistral 7B** via **Ollama**, designed to simulate a multilingual customer support assistant. It is part of our GENAI_003_PROJECT_XX submission for the MSA 8700 course.

---

## ğŸ“Œ Project Description

The chatbot answers customer queries related to:
- Order status
- Return and refund policies
- Shipping timelines
- Product concerns
- Escalation to human support

Our backend logic is powered by a **local LLM (Mistral)** using [Ollama](https://ollama.com/), ensuring:
- âœ… No API key needed
- âœ… Zero cost to run
- âœ… Full control over chatbot behavior
- âœ… Offline capability

---

## ğŸ§  Technology Stack

| Component     | Tool / Library       |
|---------------|----------------------|
| LLM Backend   | Mistral 7B via Ollama |
| Interface     | Python CLI (Terminal) |
| Dev Platform  | macOS (local)         |
| Deployment    | Localhost (optional: Streamlit Cloud) |

---

## ğŸ‘¨â€ğŸ’» Project Team & Roles

| Name     | Role                          | Responsibilities |
|----------|-------------------------------|------------------|
| Tanuj    | Project Lead / LLM Engineer   | Developed chatbot logic, integrated Mistral via Ollama |
| Vish     | Full Stack Developer          | Streamlit UI, backend API, deployment (in progress) |
| Abhay    | UX & Testing Lead             | Chat flow design, feedback logging, UX polish |

---

## ğŸš€ Getting Started

### ğŸ”§ Prerequisites
- [Install Ollama](https://ollama.com/download)
- Pull Mistral:
  ```bash
  ollama pull mistral
